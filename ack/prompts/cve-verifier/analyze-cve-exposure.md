---
name: analyze-cve-exposure
description: CVE exposure analysis combining phase 2 and phase 4 workflows
tags: [cve, security, analysis, exposure, vulnerability, cve-verifier]
---

## Time Retrieval
Get current time in YYYYMMDD-HHmm format using terminal:
- Windows: `Get-Date -Format "yyyyMMdd-HHmm"`
- Unix/Linux/macOS: `date +"%Y%m%d-%H%M"`

Use terminal commands, not training data.

## Input Parameters
- **cve_id**: string - CVE identifier (format: CVE-YYYY-NNNNN)
- **blackduck_csv_path**: string - Path to BlackDuck CSV file for dependency validation
- **output_directory**: string - Directory containing CVE descriptors and for saving analysis results

## Previous Steps or Phase
1. CVE descriptor has been created and validated
2. Code consolidation files (llms-full.txt, llms.txt) exist in output directory
3. BlackDuck CSV data is available for dependency validation
4. Analysis tasklist identifies CVEs requiring exposure analysis

## Process

1. **Update Analysis Tasklist** (MANDATORY FIRST STEP):
   - Execute script: `[id:tools_dir]/cve-verifier/update-tasklist.ps1` with parameters:
     - `-Tasklist_type "Analysis"`
     - `-Blackduck_CSV` set to blackduck_csv_path
   - Review updated tasklist to identify next priority CVE requiring analysis
   - Verify CVE from tasklist matches cve_id parameter

2. **Validate Prerequisites**:
   - Verify CVE descriptor exists at `{output_directory}/individual-cve-descriptors/{cve_id}-descriptor.json`
   - Check if analysis already exists at `{output_directory}/individual-cve-analyses/{cve_id}-analysis.json`
   - Confirm codebase files exist: `{output_directory}/llms-full.txt` and `{output_directory}/llms.txt`
   - Skip if analysis exists, proceed if missing

3. **Extract Discovery Patterns from Descriptor** (MANDATORY EXTRACTION):
   - Load CVE descriptor file for cve_id
   - Extract ALL discovery patterns from descriptor.discovery_instruction:
     - `import_patterns`: Direct, wildcard, static imports
     - `method_invocation_patterns`: Vulnerable method calls
     - `configuration_file_patterns`: Config file patterns
     - `dependency_declaration_patterns`: Maven/Gradle patterns
     - `framework_integration_patterns`: Framework-specific usage
   - **VERIFICATION**: ALL pattern categories must be extracted - missing categories invalidate analysis

4. **Execute Pattern-Based Code Search** (COMPREHENSIVE SEARCH REQUIRED):
   - **CRITICAL**: Use `run_command` with `rg` (ripgrep) for all searches - DO NOT use `grep_search` tool
   - **Search Command Format**: `rg "pattern" {output_directory}/llms-full.txt`
   - For each pattern category, execute comprehensive searches in llms-full.txt:
     - **Import Pattern Search**: Search codebase for each import pattern (EXACT MATCHES)
       - Example: `rg "import org.apache.log4j" llms-full.txt`
       - Use regex patterns when needed: `rg "import.*log4j" llms-full.txt`
     - **Method Invocation Search**: Search for vulnerable method calls (CASE SENSITIVE)
       - Example: `rg "SocketServer\.main\(" llms-full.txt`
       - Use escaped regex for special characters
     - **Configuration Search**: Search configuration files for vulnerable settings
       - Example: `rg "log4j\.properties" llms-full.txt`
     - **Dependency Search**: Search POM/build files for library declarations
       - Example: `rg "log4j:log4j:1\." llms-full.txt`
       - Use regex for version patterns
     - **Framework Integration Search**: Search for framework-specific usage
       - Example: `rg "spring.*log4j.*1\." llms-full.txt`
   - **MANDATORY DOCUMENTATION**: Record EACH search with:
     - Exact ripgrep command executed
     - Pattern searched
     - Matches found (with line numbers from ripgrep output)
     - File locations (from ripgrep output)
     - **Code snippets**: Extract actual code lines containing matches (minimum 20 lines context)
     - **File content**: Capture relevant file sections for detailed analysis
   - **EVIDENCE COLLECTION**: For each match found:
     - Extract surrounding code context (minimum 5 lines before/after match)
     - Identify file paths and exact locations
     - Capture method signatures and class contexts where applicable
   - **VERIFICATION**: ALL patterns from descriptor MUST be searched using ripgrep - NO exceptions

5. **Analyze Results Using CVE Context and Found Code Evidence**:
   - **Input for Analysis**: Use collected evidence from step 4:
     - Code snippets with context from pattern matches
     - File locations and line numbers
     - Relevant file sections containing vulnerable patterns
   - Use CVE descriptor context for comprehensive analysis:
     - **Vulnerability Description**: Understanding specific vulnerability mechanism
     - **Affected Library**: Exact library and version information
     - **Vulnerable API**: Specific classes/methods that are vulnerable
     - **Attack Vector Information**: How vulnerability can be exploited
   - **Code-Specific Analysis**: For each code evidence found:
     - Analyze actual usage patterns in found code snippets
     - Evaluate if vulnerable methods are called with user-controlled input
     - Assess configuration settings in context of found files
     - Determine if framework integration exposes vulnerability
   - **Evidence-Based Risk Classification**:
     - **DIRECTLY_EXPOSED**: Vulnerable code found with user-controlled input paths (cite specific code)
     - **POTENTIALLY_EXPOSED**: Vulnerable code present but exploitation unclear (reference found patterns)
     - **LOW_RISK**: Library present but vulnerable code not used (show evidence of safe usage)
     - **NOT_EXPOSED**: No vulnerable code patterns found
     - **INVALID_CVE**: CVE disputed, withdrawn, or misattributed

6. **Create Individual CVE Analysis File**:
   - Use template: `[id:templates_dir]/cve-verifier/cve-analysis-template.json`
   - Populate comprehensive analysis with:
     - Executive summary with risk classification
     - Detailed vulnerability assessment
     - Code search results and evidence
     - Attack vector feasibility analysis
     - Specific remediation recommendations
   - Save as: `{output_directory}/individual-cve-analyses/<project_name>_{cve_id}-analysis.json`

7. **Session Management and Progress Update**:
   - Execute automated progress update: `[id:tools_dir]/cve-verifier/update-tasklist.ps1` with parameters:
     - `-Tasklist_type "Analysis"`
     - `-Blackduck_CSV` set to blackduck_csv_path
   - Verify analysis creation completed successfully
   - Update tasklist to reflect completion status

## Output Format
- CVE analysis file: `{output_directory}/individual-cve-analyses/<project_name>_{cve_id}-analysis.json`
- Updated analysis tasklist showing completion progress
- Comprehensive exposure assessment with evidence

## Output to USER
- Confirmation message: "CVE exposure analysis completed for {cve_id}"
- Risk classification result with confidence level
- Analysis file location with validation status
- Evidence summary and key findings

### ‚úÖ CVE Analysis Complete - Session Handoff

**Completed CVE**: {cve_id}
- **Analysis File**: `{output_directory}/individual-cve-analyses/{project-name}_{cve_id}-analysis.json`
- **Risk Classification**: [Display result with confidence level]
- **Next Priority**: [Show next CVE from updated tasklist]

### üîÑ To Continue Workflow - Follow These Exact Steps:
1. **Start New Session** with the agent
2. **Ask**: `"cve exposure"`
3. The agent will process the next CVE descriptor or complete the workflow

**‚ö†Ô∏è Session must end here. Please start a new session and ask "execute this workflow" to continue.**

## CVE-Verifier Domain Rules
- Rule 1: Use ONLY CVE descriptor file as source of vulnerability information (NEVER BlackDuck CSV)
- Rule 2: ALL discovery patterns from descriptor must be searched comprehensively
- Rule 3: Evidence-based risk classification with detailed justification required
- Rule 4: Mandatory session handoff after each CVE completion - no continuing to next CVE
- Rule 5: Progress update script must be executed after each completion
- Rule 6: Analysis must reference specific code locations and attack vector feasibility
