#!/usr/bin/env python3
"""
Documentation Generator Script

Generates comprehensive documentation by consolidating project files into a single text file.
Based on PowerShell generate-llms-txt.ps1 from OLAF toolkit.

This script processes project files and creates either a full documentation file
with complete file contents or a structure-only documentation showing file organization.
"""

import argparse
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Set


def get_file_extensions() -> Set[str]:
    """Get default file extensions to process."""
    return {'.md', '.py', '.js', '.ts', '.json', '.txt', '.ps1', '.java'}


def should_process_file(file_path: Path, max_size_bytes: int = 500 * 1024) -> bool:
    """
    Check if file should be processed based on size and type.
    
    Args:
        file_path: Path to the file
        max_size_bytes: Maximum file size in bytes (default 500KB)
        
    Returns:
        True if file should be processed
    """
    try:
        return file_path.stat().st_size < max_size_bytes
    except (OSError, IOError):
        return False


def read_file_content(file_path: Path) -> str:
    """
    Read file content with error handling.
    
    Args:
        file_path: Path to the file to read
        
    Returns:
        File content as string, or empty string if error
    """
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read()
    except (OSError, IOError, UnicodeDecodeError) as e:
        print(f"Warning: Could not read {file_path}: {e}")
        return ""


def get_relative_path(file_path: Path, base_path: Path) -> str:
    """
    Get relative path from base path.
    
    Args:
        file_path: Full path to file
        base_path: Base path to calculate relative from
        
    Returns:
        Relative path as string
    """
    try:
        return str(file_path.relative_to(base_path))
    except ValueError:
        return str(file_path)


def find_files(root_path: Path, extensions: Set[str]) -> List[Path]:
    """
    Find all files with specified extensions in the directory tree.
    
    Args:
        root_path: Root directory to search
        extensions: Set of file extensions to include
        
    Returns:
        List of Path objects for matching files
    """
    files = []
    
    try:
        for file_path in root_path.rglob('*'):
            if (file_path.is_file() and 
                file_path.suffix.lower() in extensions and
                should_process_file(file_path)):
                files.append(file_path)
    except (OSError, IOError) as e:
        print(f"Error scanning directory {root_path}: {e}")
    
    return sorted(files)


def generate_full_documentation(root_path: Path, files: List[Path]) -> List[str]:
    """
    Generate full documentation with complete file contents.
    
    Args:
        root_path: Root directory path
        files: List of files to process
        
    Returns:
        List of content lines
    """
    content = []
    
    for file_path in files:
        relative_path = get_relative_path(file_path, root_path)
        print(f"Processing: {relative_path}")
        
        content.append(f"## File: {relative_path}")
        content.append("")
        
        file_content = read_file_content(file_path)
        
        if file_path.suffix.lower() == '.md':
            content.append(file_content)
        else:
            content.append("```")
            content.append(file_content)
            content.append("```")
        
        content.append("")
        content.append("---")
        content.append("")
    
    return content


def generate_structure_documentation(root_path: Path, files: List[Path]) -> List[str]:
    """
    Generate structure-only documentation showing file organization.
    
    Args:
        root_path: Root directory path
        files: List of files to process
        
    Returns:
        List of content lines
    """
    content = []
    
    for file_path in files:
        relative_path = get_relative_path(file_path, root_path)
        print(f"Processing: {relative_path}")
        
        content.append(f"## File: {relative_path}")
        content.append("")
        content.append("---")
        content.append("")
    
    return content


def main():
    """Main function."""
    parser = argparse.ArgumentParser(
        description="Generate documentation by consolidating project files",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s my-project
  %(prog)s my-project --output docs.txt --mode Structure
  %(prog)s /path/to/project --output /full/path/to/output.txt
        """
    )
    
    parser.add_argument(
        'path',
        help='Path to the project directory to process'
    )
    
    parser.add_argument(
        '-o', '--output',
        default='llms-full.txt',
        help='Output file path (default: llms-full.txt)'
    )
    
    parser.add_argument(
        '-m', '--mode',
        choices=['Full', 'Structure'],
        default='Full',
        help='Documentation mode: Full (with content) or Structure (files only) (default: Full)'
    )
    
    parser.add_argument(
        '--extensions',
        nargs='+',
        help='File extensions to include (with dots, e.g., .py .js .md)'
    )
    
    parser.add_argument(
        '--max-size',
        type=int,
        default=500,
        help='Maximum file size in KB to process (default: 500)'
    )
    
    args = parser.parse_args()
    
    # Validate input path
    root_path = Path(args.path).resolve()
    if not root_path.exists():
        print(f"Error: Path does not exist: {root_path}", file=sys.stderr)
        sys.exit(1)
    
    if not root_path.is_dir():
        print(f"Error: Path is not a directory: {root_path}", file=sys.stderr)
        sys.exit(1)
    
    # Set up file extensions
    if args.extensions:
        extensions = {ext if ext.startswith('.') else f'.{ext}' for ext in args.extensions}
    else:
        extensions = get_file_extensions()
    
    # Convert max size to bytes
    max_size_bytes = args.max_size * 1024
    
    # Initialize content
    content = []
    content.append(f"# {root_path.name} Documentation")
    content.append("")
    content.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    content.append("")
    
    # Add README if exists
    readme_path = root_path / "README.md"
    if readme_path.exists():
        content.append("## Overview")
        content.append("")
        readme_content = read_file_content(readme_path)
        content.append(readme_content)
        content.append("")
    
    # Find files to process
    print(f"Scanning {root_path} for files with extensions: {', '.join(sorted(extensions))}")
    files = find_files(root_path, extensions)
    
    # Filter by size
    files = [f for f in files if should_process_file(f, max_size_bytes)]
    
    print(f"Found {len(files)} files to process")
    
    # Generate content based on mode
    if args.mode == 'Full':
        content.extend(generate_full_documentation(root_path, files))
    else:  # Structure
        content.extend(generate_structure_documentation(root_path, files))
    
    # Determine output path
    output_path = Path(args.output)
    if not output_path.is_absolute():
        output_path = Path.cwd() / output_path
    
    # Create output directory if needed
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Write output file
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))
        
        print(f"Generated: {output_path}")
        print(f"Files processed: {len(files)}")
        
    except (OSError, IOError) as e:
        print(f"Error writing output file {output_path}: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()